# -*- coding: utf-8 -*-
"""stock_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mBBBjrjST28oET10dI-xrX-ZfaqDv2dk
"""

# streamlit_app.py

import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from keras.models import load_model
import datetime

st.set_page_config(page_title="ðŸ“ˆ Stock Price Prediction", layout="wide")

st.title("Stock Price Prediction App ðŸ“Š")
st.markdown("Predict future stock prices using historical data and deep learning (LSTM)")

# User inputs
stock = st.text_input("Enter Stock Ticker (e.g., AAPL, TSLA)", value='AAPL')
start_date = st.date_input("Start Date", value=datetime.date(2010, 1, 1))
end_date = st.date_input("End Date", value=datetime.date.today())

# Load data
if st.button("Load and Predict"):
    df = yf.download(stock, start=start_date, end=end_date)
  
# Safety checks after downloading stock data
st.write("Downloaded Columns:", df.columns)

if df.empty:
    st.error("No data found for the selected stock or date range.")
    st.stop()

if 'Close' not in df.columns:
    st.error("Error: 'Close' column is missing. Please check the stock ticker.")
    st.stop()

# Ensure no extra spaces in column names
df.columns = df.columns.str.strip()

# Proceed only if 'Close' exists after cleaning
if 'Close' not in df.columns:
    st.error("Cleaned DataFrame still missing 'Close' column.")
    st.stop()

# Drop rows where Close is NaN
if df['Close'].isnull().all():
    st.error("All values in 'Close' column are NaN.")
    st.stop()

df.dropna(subset=['Close'], inplace=True)

if df['Close'].empty:
    st.error("No valid 'Close' price data after cleaning. Try a different date range or stock.")
    st.stop()

    st.subheader("Raw Data")
    st.write(df.tail())
    

    # Plot closing price
    st.subheader("Closing Price Over Time")
    fig = plt.figure(figsize=(12, 6))
    plt.plot(df.Close)
    st.pyplot(fig)
    

    # Preprocessing
    data = df.filter(['Close'])
    dataset = data.values
    training_data_len = int(np.ceil(len(dataset) * 0.8))

    scaler = MinMaxScaler(feature_range=(0,1))
    scaled_data = scaler.fit_transform(dataset)

    train_data = scaled_data[0:training_data_len]
    x_train, y_train = [], []

    for i in range(60, len(train_data)):
        x_train.append(train_data[i-60:i, 0])
        y_train.append(train_data[i, 0])

    x_train, y_train = np.array(x_train), np.array(y_train)
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

    # Load pre-trained model
    try:
        model = load_model('lstm_model.h5')
        st.success("Model loaded successfully!")
    except:
        st.error("Could not load model. Please train and save `lstm_model.h5` first.")
        st.stop()

    # Prepare test data
    test_data = scaled_data[training_data_len - 60:]
    x_test = []
    for i in range(60, len(test_data)):
        x_test.append(test_data[i-60:i, 0])

    x_test = np.array(x_test)
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    predictions = model.predict(x_test)
    predictions = scaler.inverse_transform(predictions)

    # Final plot
    train = data[:training_data_len]
    valid = data[training_data_len:]
    valid['Predictions'] = predictions

    st.subheader("Predictions vs Actual")
    fig2 = plt.figure(figsize=(12, 6))
    plt.plot(train['Close'], label='Train')
    plt.plot(valid['Close'], label='Actual')
    plt.plot(valid['Predictions'], label='Predicted')
    plt.legend()
    st.pyplot(fig2)

